# ASCII-Art-VLM: Enhancing LLM Comprehension of ASCII Art via Vision-Language Models  

![ASCII Art Example](https://via.placeholder.com/400x200?text=ASCII+Art+to+Image+Demo)  

This repository implements an inference-time system to improve Large Language Model (LLM) understanding of ASCII art by leveraging Vision-Language Models (VLMs). The pipeline:  
1. **Detects** ASCII art in text inputs.  
2. **Converts** it into an image.  
3. **Routes** the image through a VLM (e.g., GPT-4V) for captioning.  
4. **Injects** the caption back into the LLM prompt for enhanced comprehension.  

## Key Features  
- üöÄ **No LLM retraining**‚Äîworks with pretrained models (tested on GPT-4).  
- üñºÔ∏è **ASCII-to-image conversion** for VLM processing.  
- üìä **Benchmarked performance** against text-only baselines.  

## Installation  
```bash
pip install -r requirements.txt  # Includes Pillow, OpenCV, and VLM APIs
